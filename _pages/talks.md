---
permalink: /talks/
title: ""
excerpt: "Talks"
author_profile: true
redirect_from:
  - /talks.html
---

- **01/2026**: I shared notes on data parallelism in training large language models - "How many GPUs do you need to train a transformer?". [[notes](/files/vram_calculation.pdf)]

- **01/2026**: I shared notes on policy gradient methods. [[notes](/files/rl_notes.pdf)]

- **09/2025**: I gave a talk titled "Orthogonality in neural network" for [Scaleout Edges](https://www.scaleoutsystems.com). [[slides](/files/ortho.pdf), [notes](/files/ortho_notes.pdf)]

- **09/2025**: I gave a talk about flow matching and diffusion models at our group seminar. [[notes](/files/flow_matching_diffusion_models.pdf), [code](https://github.com/li-ju666/flow_and_diffusion_model/tree/master)]

- **06/2025**: I gave my half-time seminar titled "Learning from distributed and heterogeneous data" for Department of Uppsala University. [[slides](/files/half_time_seminar.pdf)]

- **06/2025**: I gave a talk about distributed and federated learning for master course Distributed and Parallel Computing as a guest lecture. [[slides](/files/pdp25.pdf)]

- **10/2024**: I gave a talk about Bayesian neural network for our group seminar. [[notes](/files/bbb.pdf)]

- **10/2024**: I gave a poster presentation titled "Is logit adjustment a free lunch for heterogeneous federated learning?" at eSSENCE 2024. [[poster](/files/fedla_poster.pdf)]

- **05/2024**: I gave a talk titled "Federated learning for predicting compound mechanism of action based on image-data from cell painting" for AI4Research Uppsala. [[slide](/files/ai4r.pdf)]

- **04/2024**: I gave a talk introducing denoising diffusion probabilistic model (DDPM) for PhD course Bayesian Inference. [[slide](/files/ddpm.pdf), [cheat-sheet for Bayesian Inference](/files/bayesian_inference_sheet.pdf)]

- **12/2023**: I gave a talk introducing federated learning from the perspective of optimization for Centre for Interdisciplinary Mathematics, Uppsala. [[slide](/files/cim_pre.pdf)]
